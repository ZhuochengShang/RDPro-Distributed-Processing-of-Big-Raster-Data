#!/bin/bash
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Runs the rdpro main JAR file using spark-submit
# Use cases:
# 1- If the lib directory exists
# "rdpro summary ..." runs the main JAR file with the given parameters and loads the dependencies
# "rdpro file.jar ..." runs the given JAR file as the App jar
# "rdpro --class com.example.abc ..." uses the given class name instead of rdpro Main and rdpro Jar as the App
# "rdpro --packages a,b,c .." merges the given packages with the default list of packages
# 2- If the lib directory does not exist
# Similar to the above but adds all the additional dependencies.
# If called for the first time, it will download the jai_core JAR file since Spark cannot download it

# Retrieve the binary directory that contains the script
BINDIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null 2>&1 && pwd )"
LIBDIR="$BINDIR/../lib"

# The packages that will be passed to the "--packages" parameter of the Spark command
# Initialize with the dependencies of rdpro that are not included in the binary package
Packages="org.mortbay.jetty:jetty:6.1.26,org.eclipse.jetty:jetty-servlet:9.4.48.v20220622,org.eclipse.jetty:jetty-server:9.4.48.v20220622,org.geotools:gt-epsg-hsql:23.0,org.geotools:gt-coverage:23.0,org.locationtech.jts:jts-core:1.17.1"

# The repositories that will be passed to the "--repositories" parameter of the Spark command
Repositories="https://repo.osgeo.org/repository/release/"

# The Spark command looks like the following
# <spark-command> <spark-args> <spark-app> <rdpro-args>

# Specify the main command of rdpro
beastJar="$LIBDIR/rdpro-spark-${version}.jar"
if [ -e "$beastJar" ]; then
  SparkApp="$beastJar"
else
  # If there is no "lib" directory, load all packages from Maven Central as a fall back
  Packages="$Packages,edu.school.org.rdpro:rdpro-spark:${version}"
  # There is no way to start Spark without a main program so we just use "."
  SparkApp="."
fi

# Download the jai-core JAR file is not exist since Spark cannot download it
JAIJAR="$LIBDIR/jai_core-1.1.3.jar"
[ -e "$JAIJAR" ] || ( mkdir -p $LIBDIR && curl -o $JAIJAR https://repo.osgeo.org/repository/geotools-releases/javax/media/jai_core/1.1.3/jai_core-1.1.3.jar )
# Do not try to load the jai_core package from Maven repository since the JAR file is not available there
ExcludePackages="javax.media:jai_core"

# Parse user commands and split into [Spark args and rdpro args]
Jars=""
SparkArgs=""
i=1
while [[ $i -le $# ]] && [[ ${!i} == -* ]]; do
  key=${!i}
  i=$((i+1))
  value=${!i}
  i=$((i+1))
  if [ $key == "--packages" ]; then
    Packages="$Packages,$value"
  elif [ $key == "--exclude-packages" ]; then
    ExcludePackages="$ExcludePackages,$value"
  elif [ $key == "--repositories" ]; then
    Repositories="$Repostories,$value"
  elif [ $key == "--jars" ]; then
    Jars="$Jars,$value"
  elif [ $key == "--class" ]; then
    # We can only have one main class. Override the default with the given one
    MainClass=$value
  else
    SparkArgs="$SparkArgs $key $value"
  fi
done
# Treat all the remaining arguments as rdpro arguments
beastArgs=${*:i}

if [ ${#beastArgs[@]} -gt 0 ]; then
  firstParam=${!i}
  shopt -s nocasematch; if [ -e ${firstParam} ] && [[ ${firstParam} =~ .jar ]]; then
    # The first argument is an existing JAR file, use it as the App jar instead of rdpro-spark-*.jar
    # Just make SparkApp empty and it will be used as desired
    SparkApp=""
  fi
fi

if [ -n "$NoApp" ]; then
  SparkApp=""
fi

for jar in $LIBDIR/*.jar; do
  :
  if [ -z "$SparkApp" ] || [ $jar != $SparkApp ]; then
    Jars="$Jars,$jar"
  fi
done
# Remove the leading comma
Jars=${Jars:1}

# Append the remaining arguments to SparkArgs
SparkArgs="$SparkArgs --packages $Packages --exclude-packages $ExcludePackages"
SparkArgs="$SparkArgs --repositories $Repositories"
SparkArgs="$SparkArgs --jars $Jars"

if [ -n "$MainClass" ]; then
  SparkArgs="$SparkArgs --class $MainClass"
fi

cmd="$SparkCommand $SparkArgs $SparkApp $beastArgs"
$cmd
